{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3b4c8-c7a3-418c-bae0-f90555fe3bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import markov\n",
    "import sys\n",
    "util_path = './utils'\n",
    "sys.path.insert(0, util_path)\n",
    "import util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report, accuracy_score, f1_score, log_loss, recall_score, precision_score \n",
    "! pip install scikit-plot\n",
    "import scikitplot as skplt\n",
    "import re\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c762d-ad16-4101-ab4f-00fe93acec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./Datasets/master_dataset.csv\").fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b07bfb-7c13-4ab0-81f9-2c694e215c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1[data1.label_sexist == 'sexist']\n",
    "ndf = data1[data1.label_sexist == 'not sexist']\n",
    "add_df = ndf.sample(2000)\n",
    "frames = [add_df,df]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b68b6-a625-4a5d-95d9-e10bbf69fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the result in a new column called 'processed_text'\n",
    "data[\"processed_text\"] = data['text'].apply(util.process_text, model=2)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedb4a4-0ed2-4dc4-a0e1-db05060eecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data['processed_text'], data['label_sexist'],stratify=data['label_sexist'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a4b73-3e16-4146-9260-d924178ffd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(i).split('/') for i in train_Y]\n",
    "text= train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613213e2-40a8-4987-a860-fc4e2728c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The code creates a Tf-idf vectorizer with a minimum document frequency of 5, \n",
    "applies it to a list of texts, then creates a multilabel binarizer and \n",
    "fits it to a list of labels. It creates arrays for the input and output features, and \n",
    "splits the data into training and test sets\"\"\"\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(min_df = 5) #max_features=3000\n",
    "x_tfidf = tfidfvectorizer.fit_transform(text).toarray()\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labels)\n",
    "Y = mlb.transform(labels)\n",
    "n_op_features = len(Y[0])\n",
    "train_x,test_x,train_y,test_y = train_test_split(x_tfidf,Y,test_size=0.2)\n",
    "n_ip_features = len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553526bc-7944-4591-915d-96043b2b0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  '''This code block converts the arrays into tensors for pytorch.'''\n",
    "  def __init__(self, X, y):\n",
    "    self.X = torch.tensor(X)\n",
    "    self.y = torch.tensor(y)\n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "  def __getitem__(self,index):\n",
    "    return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5588f7-bc99-4146-9229-da4a7810354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Definition\n",
    "batch_size = 128\n",
    "train_ds = TextDataset(X=train_x, y=train_y)\n",
    "test_ds = TextDataset(X=test_x, y=test_y)\n",
    "dataloader_train = DataLoader(dataset=train_ds,batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbf8f3-2dc7-4d63-b000-2498d61b295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  '''Multi-layered perceptron based classifier'''\n",
    "  def __init__(self, num_features,out_features):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_features (int): the size of the input feature vector\n",
    "    \"\"\"\n",
    "    super(MLP, self).__init__()\n",
    "    self.fc1 = nn.Linear(in_features=num_features, out_features=64)\n",
    "    print(\"num f:\", num_features)\n",
    "    self.fc2 = nn.Linear(in_features=64,out_features=32)\n",
    "    self.fc3 = nn.Linear(in_features=32,out_features=out_features)\n",
    "\n",
    "  def forward(self, x_in, apply_softmax=False):\n",
    "    \"\"\"The forward pass of the classifier\n",
    "    \n",
    "    Args:\n",
    "        x_in (torch.Tensor): an input data tensor. \n",
    "            x_in.shape should be (batch, num_features)\n",
    "        apply_softmax (bool): a flag for the sigmoid activation\n",
    "            should be false if used with the Cross Entropy losses\n",
    "    Returns:\n",
    "        the resulting tensor. tensor.shape should be (batch,)\n",
    "    \"\"\"\n",
    "    y_out_1 = torch.relu(self.fc1(x_in))\n",
    "    y_out_2 = self.fc2(y_out_1)\n",
    "    y_out = self.fc3(y_out_2)\n",
    "    return y_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc5338-427d-4904-a21c-1b26338d02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da26aa1-f5bb-4ae8-baea-911fda1f7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markov import Project, ProjectScope\n",
    "\n",
    "# Create a new project\n",
    "my_project = Project(\n",
    "    # project name\n",
    "    name=\"Final Project AI4SG\",\n",
    "    # project description (optional)\n",
    "    description=\"Visualizing the model-1 and model-2\",\n",
    "    # project visibility (optional; public by default)\n",
    "    project_scope=ProjectScope.PUBLIC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b0ef9-04d6-4f8b-bce4-94a717e6b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "learning_rate=0.0001\n",
    "num_epochs=45\n",
    "hyper_parameters = {\"learning_rate\":0.0001,\"num_epochs\":45}\n",
    "epoch_loss_list=[]\n",
    "epoch_acc_list=[]\n",
    "val_epoch_acc_list=[]\n",
    "val_epoch_loss_list=[]\n",
    "\n",
    "model = MLP(n_ip_features,n_op_features)\n",
    "model.to(device)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_iter=math.ceil(len(train_ds)/batch_size)\n",
    "# print(n_iter)\n",
    "\n",
    "\n",
    "# Use the ExperimentRecorder constuctor provided by the MarkovML SDK\n",
    "# to create a new experiment recorder\n",
    "recorder = markov.ExperimentRecorder(\n",
    "    # Name of the experiment recording\n",
    "    name=\"Model 2 TFIDF MLP experiment\",\n",
    "    # Project associated with the experiment\n",
    "    project_id=my_project.project_id,\n",
    "    # project_id=\"3Tfz2jR4xNF23H\",\n",
    "    # Hyper-parameters used for model training\n",
    "    hyper_parameters = {\"learning_rate\":0.0001,\"num_epochs\":45},\n",
    "    # Additional notes (optional)\n",
    "    model_class=markov.ModelClass.TAGGING,\n",
    "    notes=\"This is a experiment describing the model-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa29795-3b4d-42aa-bd1f-4a1730ac3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "with recorder:\n",
    "    for epoch in range(num_epochs):\n",
    "      epoch_loss = 0\n",
    "      epoch_acc=0\n",
    "      val_epoch_loss=0\n",
    "      val_epoch_acc=0\n",
    "      for k,(X,y) in enumerate(dataloader_train):\n",
    "        # the training routine is these 5 steps:\n",
    "\n",
    "        # step 1. load the data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # step 2. compute the output\n",
    "        y_pred = model(x_in=X.float())\n",
    "        y_1 = (y_pred).to('cpu').detach().numpy()\n",
    "        y_1=(np.array(y_1) >= 0)*1\n",
    "        y_0=y.to('cpu').detach().numpy()\n",
    "        acc = sum([(y_0[i]==y_1[i]).all()*1 for i in range(len(y_0))])\n",
    "        epoch_acc+= acc\n",
    "       \n",
    "\n",
    "    # step 3. compute the loss\n",
    "        loss = loss_func(y_pred, y.squeeze(1).float())\n",
    "        epoch_loss+= loss.item()\n",
    "\n",
    "    # step 4. use loss to produce gradients\n",
    "        loss.backward()\n",
    "\n",
    "    # step 5. use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "      epoch_loss = round(epoch_loss/(k+1),3)\n",
    "      epoch_loss_list.append(epoch_loss)\n",
    "      epoch_acc = round(epoch_acc/len(train_ds),3)\n",
    "      epoch_acc_list.append(epoch_acc)\n",
    "  \n",
    "      for k,(X,y) in enumerate(dataloader_test):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x_in=X.float())\n",
    "        y_1 = (y_pred).to('cpu').detach().numpy()\n",
    "        y_1=(np.array(y_1) >= 0)*1\n",
    "        y_0=y.to('cpu').detach().numpy()\n",
    "        val_acc = sum([(y_0[i]==y_1[i]).all()*1 for i in range(len(y_0))])\n",
    "        val_epoch_acc+=val_acc\n",
    "        loss = loss_func(y_pred, y.squeeze(1).float())\n",
    "        val_epoch_loss+= loss.item()\n",
    "\n",
    "      val_epoch_acc=round(val_epoch_acc/len(test_ds),3)\n",
    "      val_epoch_acc_list.append(val_epoch_acc)\n",
    "      val_epoch_loss = round(val_epoch_loss/(k+1),3)\n",
    "      val_epoch_loss_list.append(val_epoch_loss)\n",
    "      print('epoch : ' + str(epoch+1)+'/'+str(num_epochs))\n",
    "      print(\"-\"*40)\n",
    "      print('loss : ' + str(epoch_loss)+ ' \\t val loss : '+ str(val_epoch_loss)+ '\\nacc :' + str(epoch_acc)+ ' \\t val acc :' + str(val_epoch_acc))\n",
    "      print(\"+\"*40)  # -----------------------------------------\n",
    "      losses.append(epoch_loss)\n",
    "      recorder.add_record({\"loss\": epoch_loss})\n",
    "      recorder.add_record({\"val_loss\": val_epoch_loss})\n",
    "      recorder.add_record({\"accuracy\": epoch_acc})\n",
    "      recorder.add_record({\"val_accuracy\": val_epoch_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42270c44-7bbe-4f54-8d26-7864ac5d84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(plot_var,train_plot_list,val_plot_list):\n",
    "  '''Function for visualizing the Accuracy and Loss'''\n",
    "  epochs = len(train_plot_list)\n",
    "  fig = plt.figure(figsize=(8,6))\n",
    "  if plot_var==\"accuracy\": plt.title(\"Train/Validation Accuracy\")\n",
    "  elif plot_var ==\"loss\" : plt.title(\"Train/Validation Loss\")\n",
    "  plt.plot(list(np.arange(epochs) + 1) , train_plot_list, label='train')\n",
    "  plt.plot(list(np.arange(epochs) + 1), val_plot_list, label='validation')\n",
    "  plt.xlabel('num_epochs', fontsize=12)\n",
    "  plt.ylabel('loss', fontsize=12)\n",
    "  plt.legend(loc='best')\n",
    "  if plot_var==\"accuracy\": plt.savefig(\"./result/model2/task_a_train_Val_accuracy.png\")\n",
    "  elif plot_var ==\"loss\" : plt.savefig(\"./result/model2/task_a_train_Val_loss.png\")\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a496567-ebc5-4070-97d6-8f94cd01b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the Accuracy and Loss\n",
    "plot_graph(\"accuracy\",epoch_acc_list, val_epoch_acc_list)\n",
    "plot_graph(\"loss\",epoch_loss_list, val_epoch_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876bbfc-bfe9-4b1c-9a77-c5c75f6b9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting testing elements to torch tensor from array\n",
    "test_x = torch.Tensor(test_x)\n",
    "y_pred = model(test_x.to(device)) \n",
    "print(y_pred.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888f3d2-26ea-463c-8e08-8a4986c3203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_predict(x):\n",
    "  '''Function to get predicted labels for testing data'''\n",
    "  x = tfidfvectorizer.transform([x]).toarray()\n",
    "  x = torch.tensor(x, dtype=torch.float64)\n",
    "  pred = model(x_in=x.float().to(device))\n",
    "  y_1 = (pred).to('cpu').detach().numpy()\n",
    "  ind=(y_1).argmax(axis = 1)\n",
    "  y_dim = y_1.shape[1]\n",
    "  l = [0 for i in range(y_dim)]\n",
    "  for i in range(y_dim):\n",
    "      if i==ind:\n",
    "          l[i] = 1\n",
    "  #y_1 = np.array(l)\n",
    "  #print(y_1)\n",
    "  y_1 = mlb.inverse_transform(np.array(l).reshape(1,2))\n",
    "  return y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573c97a-6e41-4fad-a1b5-c6d89caa6f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting relations for plotting Confusion Matrix\n",
    "test_utterences= test_X\n",
    "predicted_relations=[]\n",
    "for utterence in test_utterences:\n",
    "  test_pred=multilabel_predict(utterence)\n",
    "  predicted_relations.append(test_pred[0])\n",
    "print(len(predicted_relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92c44b-8d79-4d64-bf99-00122f859111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Confusion Matrix\n",
    "y_true = [x for x in test_Y]\n",
    "y_pred = [x for x in predicted_relations]\n",
    "skplt.metrics.plot_confusion_matrix(y_true, y_pred, figsize=(8,8),x_tick_rotation=90)\n",
    "plt.savefig(\"./result/model2/task_a_confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7ea45-5cc5-42bb-8b4c-38b017bc220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Report\n",
    "print(classification_report(y_true,y_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_true,y_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(\"./result/model2/task_a_classification_report.csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b4b02-2488-4c0e-8f4c-a04d93945409",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {'actual': y_true, 'predicted': y_pred} ## see which variables to take from accuracy_score line in previous code block\n",
    "df_markov = pd.DataFrame(data=dict_data)\n",
    "# df_markov.replace({'not_sexist': 0, 'sexist': 1}, inplace=True)\n",
    "df_markov.to_csv(\"./result/model2/recording_model2.csv\")\n",
    "df_markov.head()\n",
    "\n",
    "# now just map the not sexist with 0 and sexist with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c70ac5-61f2-4389-8d5b-9f1a5823d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./result/model2/trained_model2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02dc11d-f6e8-4c53-a9ff-4b81226fddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./result/model2/trained_model2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde13ec-86ba-429a-ad8b-c6e4200042f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sexism(x):\n",
    "  x = tfidfvectorizer.transform([x]).toarray()\n",
    "  x = torch.tensor(x, dtype=torch.float64)\n",
    "  model.load_state_dict(torch.load('./result/model2/trained_model2.pth'))\n",
    "  pred = model(x_in=x.float().to(device))\n",
    "  y_1 = (pred).to('cpu').detach().numpy()\n",
    "  ind=(y_1).argmax(axis = 1)\n",
    "  y_dim = y_1.shape[1]\n",
    "  l = [0 for i in range(y_dim)]\n",
    "  for i in range(y_dim):\n",
    "      if i==ind:\n",
    "          l[i] = 1\n",
    "  y_1 = mlb.inverse_transform(np.array(l).reshape(1,2))\n",
    "  return y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa860f0c-1ab8-471c-80ec-92505792e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = \"women are weak and inferior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29336f-1f88-496d-acc2-a26a15b3db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=predict_sexism(t1)\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b50bd-e125-4360-8821-a2b2359e4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markov import EvaluationRecorder\n",
    "evaluation_recorder = EvaluationRecorder(\n",
    "    name=f\"Evaluating {recorder.name}\",\n",
    "    notes=f\"Evaluation of model2 using MarkovML\",\n",
    "    model_id=recorder.model_id\n",
    ")\n",
    "\n",
    "evaluation_recorder.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b642ed2-3307-4fc5-8887-02e22e1d5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "from markov.api.schemas.model_recording import SingleTagInferenceRecord\n",
    "\n",
    "# create and register the recorder\n",
    "filepath = os.path.join('./result/model2/recording_model2.csv')\n",
    "with open(filepath) as f:\n",
    "    for line in f:\n",
    "        # Assign a unique identifier for individual records\n",
    "        record_id = str(uuid.uuid4())\n",
    "        tokens = line.strip('\\n').split(',')\n",
    "        record = SingleTagInferenceRecord(\n",
    "            urid=record_id,\n",
    "            inferred=tokens[2],\n",
    "            actual=tokens[1],\n",
    "            score=float(tokens[0])\n",
    "        )\n",
    "        evaluation_recorder.add_record(record)\n",
    "outcome = evaluation_recorder.finish()\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6733c13a-fcc1-456a-8b98-e36c70d3d01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46f1ca-cca4-4247-9c72-cffb066ac308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40bc42acb4d79b213bbfcc5aa1d82218001a40dca0d0520bfda7bab961b9781a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
