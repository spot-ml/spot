{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01baa4de-2e02-464a-a273-ded00286c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import markov\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "util_path = './utils'\n",
    "sys.path.insert(0, util_path)\n",
    "import preprocessing as pp\n",
    "# from markov.api.model import ModelRecorder\n",
    "# from markov.api.recording.experiments.integrations.keras.keras_auto_record import auto_record\n",
    "# from markov.api.recording.integrations.keras.keras_auto_record import auto_record\n",
    "# from markov.api.schemas.model_recording import ModelRecordingConfig, SingleTagInferenceRecord\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, log_loss, recall_score, precision_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43bc611-f240-44cb-a57d-59c2d0d8e17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = os.path.join(os.path.curdir, \"Datasets\", \"master_dataset.csv\")\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d979b30-83b8-4079-85b6-3a95c3979c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Damn, this writing was pretty chaotic</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>damn writing pretty chaotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah, and apparently a bunch of misogynistic v...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>yeah apparently bunch misogynistic virgin one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How the FUCK is this woman still an MP!!!???</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>fuck woman still mp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understand. Know you're right. At same time I ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>understand know youre right time know isnt eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surprized they didn't stop and rape some women</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>surprized didnt stop rape woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yeah but in order to keep the benefit i have t...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>yeah order keep benefit good tommorow told cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hahaha I just wish they would live their truth...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>hahaha wish would live truth cut shit wouldnt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>head mod said she talked to him after he made ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>head mod said talked made post wont tell anyon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>just the inside of your wallet: cash, bank car...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>inside wallet cash bank card credit card debit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We most definitely did. I didn’t go too much i...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>definitely didnt go much detail happened put s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label_sexist  \\\n",
       "0              Damn, this writing was pretty chaotic   not sexist   \n",
       "1  Yeah, and apparently a bunch of misogynistic v...   not sexist   \n",
       "2       How the FUCK is this woman still an MP!!!???   not sexist   \n",
       "3  Understand. Know you're right. At same time I ...   not sexist   \n",
       "4     Surprized they didn't stop and rape some women   not sexist   \n",
       "5  yeah but in order to keep the benefit i have t...   not sexist   \n",
       "6  Hahaha I just wish they would live their truth...   not sexist   \n",
       "7  head mod said she talked to him after he made ...   not sexist   \n",
       "8  just the inside of your wallet: cash, bank car...       sexist   \n",
       "9  We most definitely did. I didn’t go too much i...   not sexist   \n",
       "\n",
       "                                      processed_text  \n",
       "0                        damn writing pretty chaotic  \n",
       "1  yeah apparently bunch misogynistic virgin one ...  \n",
       "2                                fuck woman still mp  \n",
       "3  understand know youre right time know isnt eno...  \n",
       "4                    surprized didnt stop rape woman  \n",
       "5  yeah order keep benefit good tommorow told cou...  \n",
       "6  hahaha wish would live truth cut shit wouldnt ...  \n",
       "7  head mod said talked made post wont tell anyon...  \n",
       "8  inside wallet cash bank card credit card debit...  \n",
       "9  definitely didnt go much detail happened put s...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_text\"] = df['text'].apply(pp.process_text, model=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c3ec8a-e840-4d5d-b0ba-7bdfc5629177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_sexist: (5831, 3)\n",
      "class_notsexist: (22937, 3)\n"
     ]
    }
   ],
   "source": [
    "class_notsexist, class_sexist = df['label_sexist'].value_counts()\n",
    "class_notsexist, class_sexist\n",
    "# # Separate class\n",
    "class_s = df[df['label_sexist'] == \"sexist\"]\n",
    "class_ns = df[df['label_sexist'] == \"not sexist\"]\n",
    "print('class_sexist:', class_s.shape)\n",
    "print('class_notsexist:', class_ns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5a2031-f6fc-4a71-b504-16afad00919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'count (target)'}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_ns_under = class_ns.sample(class_sexist+1000)\n",
    "df_under = pd.concat([class_ns_under, class_s], axis=0)\n",
    "df_under['label_sexist'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15db0a54-4089-45f5-b54e-382513c5d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_text_vec = tfidf.fit_transform(df_under.processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d65011-5465-4644-a198-f6ff118b8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(tfidf_text_vec, df_under['label_sexist'], test_size=0.2, train_size=0.8, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2ac03-0c18-4c6f-9977-ab1c344a3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from markov import Project, ProjectScope\n",
    "\n",
    "# # Create a new project\n",
    "# my_project = Project(\n",
    "#     # project name\n",
    "#     name=\"Final Project AI4SG\",\n",
    "#     # project description (optional)\n",
    "#     description=\"Visualizing the model-1 and model-2\",\n",
    "#     # project visibility (optional; public by default)\n",
    "#     project_scope=ProjectScope.PUBLIC,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470c0702-683f-4494-998a-d6577c91d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Creating Model Model creation successful!\n",
      "✔ Registering Hyper Parameter Recorder with Markov Backend. Recorder successfully registered.\n",
      "ℹ You can view the experiment at \u001b\\https://app.markovml.com/wsp-27m23rbvum/proj/3GEEgreNQVvGxs/experiments/hp-9VZQU7kpze6FoUJL77ciKwF\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import markov\n",
    "\n",
    "hyper_parameters = {\"random_state\":0,\"n_estimators\":10,\"max_iter\":100}\n",
    "lrm = LogisticRegression(penalty='l2', random_state=0,max_iter=100,class_weight='balanced')\n",
    "\n",
    "\n",
    "\n",
    "# Use the ExperimentRecorder constuctor provided by the MarkovML SDK\n",
    "# to create a new experiment recorder\n",
    "recorder_lr = markov.ExperimentRecorder(\n",
    "    # Name of the experiment recording\n",
    "    name=\"Model 1 Logistic Regression experiment\",\n",
    "    # Project associated with the experiment\n",
    "    # project_id=my_project.project_id,\n",
    "    project_id = \"3GEEgreNQVvGxs\",\n",
    "    # Hyper-parameters used for model training\n",
    "    hyper_parameters = {\"random_state\":0,\"n_estimators\":10,\"max_iter\":100},\n",
    "    # Additional notes (optional)\n",
    "    model_class=markov.ModelClass.TAGGING,\n",
    "    notes=\"This is a experiment describing the model-1 Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3f403e-613b-445f-b85a-e53accfc3b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Starting recorder to track training data on markov backend.\n",
      "⚠ Please wait while we send the remaining data to the markov backend... Could not send all QUEUE_MESSAGE_TYPEs to the markov server!\n",
      "Accuracy: 78.72%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.81      0.80      0.81      1401\n",
      "      sexist       0.76      0.77      0.76      1132\n",
      "\n",
      "    accuracy                           0.79      2533\n",
      "   macro avg       0.78      0.79      0.79      2533\n",
      "weighted avg       0.79      0.79      0.79      2533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with recorder_lr:\n",
    "    lrm = lrm.fit(x_train_a, y_train_a,sample_weight=np.full(len(y_train_a),1))\n",
    "    lrm_pred = lrm.predict(x_test_a)\n",
    "    acc = accuracy_score(lrm_pred, y_test_a)\n",
    "    recorder_lr.add_record({\"accuracy\": acc})\n",
    "    cr = classification_report(y_test_a, lrm_pred)\n",
    "    recorder_lr.add_record({\"classification_report\": cr})\n",
    "    cm = confusion_matrix(lrm_pred, y_test_a)\n",
    "    recorder_lr.add_record({\"confusion_matrix\": cm})\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a, lrm_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a, lrm_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result/model1\", \"task_a_cls_report_logistic_reg.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244348f1-42e3-4ab0-aec1-70bac4555561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7872088432688512\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model\n",
    "filename = './result/model1/Logistic Regression/logistic_regression_model.sav'\n",
    "pickle.dump(lrm, open(filename, 'wb'))\n",
    "\n",
    "# load the model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_test_a, y_test_a)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f224f6-2dee-4dfb-adc1-791e99014bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexist\n"
     ]
    }
   ],
   "source": [
    "def predict_sexism(text, model, tfidf, lemmatizer, stop_words):\n",
    "    text = process_text(text, lemmatizer, stop_words)\n",
    "    text_vec = tfidf.transform([text])\n",
    "    prediction = model.predict(text_vec)\n",
    "    return prediction[0]\n",
    "\n",
    "# test the function\n",
    "example_text = \"I was told no woman who had children under the age of 6 had any business being outside the home.\"\n",
    "pred = predict_sexism(example_text, loaded_model, tfidf, lemmatizer, stop_words)\n",
    "print(pred) # should print 'not sexist' or 'sexist'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c31d62fe-31d9-467e-9fc8-516e072c61d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18043</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23724</th>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17758</th>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual   predicted\n",
       "18043  not sexist      sexist\n",
       "2332   not sexist      sexist\n",
       "23724      sexist      sexist\n",
       "17758      sexist  not sexist\n",
       "1476   not sexist      sexist"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dict_data = {'actual': y_test_a, 'predicted': lrm_pred} ## see which variables to take from accuracy_score line in previous code block\n",
    "df_markov = pd.DataFrame(data=dict_data)\n",
    "df_markov.to_csv(\"./result/model1/Logistic Regression/recording_lr.csv\")\n",
    "df_markov.head()\n",
    "\n",
    "# now just map the not sexist with 0 and sexist with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f44244-e8d9-4055-8137-8b41cb701d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markov.api.recording.evaluations.evaluation_recorder.EvaluationRecorder at 0x7f609c3e7d00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from markov import EvaluationRecorder\n",
    "evaluation_recorder_lr = EvaluationRecorder(\n",
    "    name=f\"Evaluating {recorder_lr.name}\",\n",
    "    notes=f\"Evaluation of model1 using MarkovML\",\n",
    "    model_id=recorder_lr.model_id\n",
    ")\n",
    "\n",
    "evaluation_recorder_lr.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74c11649-8668-4455-be49-3e7a32cc3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload Progress : 100%|██████████| 3/3 [00:00<00:00,  3.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationRecordingFinishResponse(count=2533, recording_id='4iTwUc4aMV3se68yG5so7wN', return_code='OK', message='', run_id='wWHwNVNYfpeAzZwYvMh')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "from markov.api.schemas.model_recording import SingleTagInferenceRecord\n",
    "\n",
    "# create and register the recorder\n",
    "filepath = os.path.join('./result/model1/Logistic Regression/recording_lr.csv')\n",
    "with open(filepath) as f:\n",
    "    for line in f:\n",
    "        # Assign a unique identifier for individual records\n",
    "        record_id = str(uuid.uuid4())\n",
    "        tokens = line.strip('\\n').split(',')\n",
    "        record = SingleTagInferenceRecord(\n",
    "            urid=record_id,\n",
    "            inferred=tokens[2],\n",
    "            actual=tokens[1],\n",
    "            score=float(tokens[0])\n",
    "        )\n",
    "        evaluation_recorder_lr.add_record(record)\n",
    "outcome = evaluation_recorder_lr.finish()\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9edc6858-4660-4015-9fdd-09abe69b1b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c79d03f2-6786-444f-b0ea-78c352df6352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Creating Model Model creation successful!\n",
      "✔ Registering Hyper Parameter Recorder with Markov Backend. Recorder successfully registered.\n",
      "ℹ You can view the experiment at \u001b\\https://app.markovml.com/wsp-27m23rbvum/proj/3GEEgreNQVvGxs/experiments/hp-kijfgCCDSi3qJCu4hrtTpbf\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import markov\n",
    "\n",
    "hyper_parameters = {\"max_features\":20}\n",
    "dt_clf = tree.DecisionTreeClassifier(criterion='entropy', max_features=20)\n",
    "\n",
    "\n",
    "# Use the ExperimentRecorder constuctor provided by the MarkovML SDK\n",
    "# to create a new experiment recorder\n",
    "recorder_dt = markov.ExperimentRecorder(\n",
    "    # Name of the experiment recording\n",
    "   name=\"Model 1 Decision Tree experiment\",\n",
    "    # Project associated with the experiment\n",
    "    # project_id=my_project.project_id,\n",
    "    project_id = \"3GEEgreNQVvGxs\",\n",
    "    # Hyper-parameters used for model training\n",
    "    hyper_parameters = {\"max_features\":20},\n",
    "    # Additional notes (optional)\n",
    "    model_class=markov.ModelClass.TAGGING,\n",
    "    notes=\"This is a experiment describing the model-1 Decision Tree\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48bde901-3b3c-4222-8003-4c1256853b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Starting recorder to track training data on markov backend.\n",
      "⚠ Please wait while we send the remaining data to the markov backend... Could not send all QUEUE_MESSAGE_TYPEs to the markov server!\n",
      "Accuracy: 63.09%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.68      0.63      0.65      1401\n",
      "      sexist       0.58      0.63      0.60      1132\n",
      "\n",
      "    accuracy                           0.63      2533\n",
      "   macro avg       0.63      0.63      0.63      2533\n",
      "weighted avg       0.63      0.63      0.63      2533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with recorder_dt:\n",
    "    dt_clf = dt_clf.fit(x_train_a, y_train_a)\n",
    "    dt_pred = dt_clf.predict(x_test_a)\n",
    "    acc = accuracy_score(dt_pred, y_test_a)\n",
    "    recorder_dt.add_record({\"accuracy\": acc})\n",
    "    cr = classification_report(y_test_a, dt_pred)\n",
    "    recorder_dt.add_record({\"classification_report\": cr})\n",
    "    cm = confusion_matrix(dt_pred, y_test_a)\n",
    "    recorder_dt.add_record({\"confusion_matrix\": cm})\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a, dt_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a, dt_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result/model1/Decision Tree/\", \"task_a_cls_report_logistic_decision_tree.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39a2b543-2e90-49cc-adad-219da44718f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6308724832214765\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model\n",
    "filename = './result/model1/Decision Tree/Decision_Tree_model.sav'\n",
    "pickle.dump(dt_clf, open(filename, 'wb'))\n",
    "\n",
    "# load the model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_test_a, y_test_a)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebd5c2b6-49d5-4268-a294-be89d8696eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not sexist\n"
     ]
    }
   ],
   "source": [
    "def predict_sexism(text, model, tfidf, lemmatizer, stop_words):\n",
    "    text = process_text(text, lemmatizer, stop_words)\n",
    "    text_vec = tfidf.transform([text])\n",
    "    prediction = model.predict(text_vec)\n",
    "    return prediction[0]\n",
    "\n",
    "# test the function\n",
    "example_text = \"I was told no woman who had children under the age of 6 had any business being outside the home.\"\n",
    "pred = predict_sexism(example_text, loaded_model, tfidf, lemmatizer, stop_words)\n",
    "print(pred) # should print 'not sexist' or 'sexist'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d607406f-896d-4f77-a705-758c46cde477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18043</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23724</th>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17758</th>\n",
       "      <td>sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual   predicted\n",
       "18043  not sexist      sexist\n",
       "2332   not sexist  not sexist\n",
       "23724      sexist      sexist\n",
       "17758      sexist  not sexist\n",
       "1476   not sexist  not sexist"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dict_data = {'actual': y_test_a, 'predicted': dt_pred} ## see which variables to take from accuracy_score line in previous code block\n",
    "df_markov = pd.DataFrame(data=dict_data)\n",
    "df_markov.to_csv(\"./result/model1/Decision Tree/recording_dt.csv\")\n",
    "df_markov.head()\n",
    "\n",
    "# now just map the not sexist with 0 and sexist with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f62bf03-a39d-4202-8a66-e61ae0d38d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markov.api.recording.evaluations.evaluation_recorder.EvaluationRecorder at 0x7f609fdf5df0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from markov import EvaluationRecorder\n",
    "evaluation_recorder_dt = EvaluationRecorder(\n",
    "    name=f\"Evaluating {recorder_dt.name}\",\n",
    "    notes=f\"Evaluation of model1 using MarkovML\",\n",
    "    model_id=recorder_dt.model_id\n",
    ")\n",
    "\n",
    "evaluation_recorder_dt.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4fdd798-0a78-41a4-832b-ea2d2c9914e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload Progress : 100%|██████████| 3/3 [00:01<00:00,  2.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationRecordingFinishResponse(count=2533, recording_id='5BHrMJG8fS3W9ZUaTGPjSoU', return_code='OK', message='', run_id='h5xSBKCz773UjzkS7UW')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "from markov.api.schemas.model_recording import SingleTagInferenceRecord\n",
    "\n",
    "# create and register the recorder\n",
    "filepath = os.path.join('./result/model1/Decision Tree/recording_dt.csv')\n",
    "with open(filepath) as f:\n",
    "    for line in f:\n",
    "        # Assign a unique identifier for individual records\n",
    "        record_id = str(uuid.uuid4())\n",
    "        tokens = line.strip('\\n').split(',')\n",
    "        record = SingleTagInferenceRecord(\n",
    "            urid=record_id,\n",
    "            inferred=tokens[2],\n",
    "            actual=tokens[1],\n",
    "            score=float(tokens[0])\n",
    "        )\n",
    "        evaluation_recorder_dt.add_record(record)\n",
    "outcome = evaluation_recorder_dt.finish()\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145f785-1c40-41cc-8f57-42c6e94d1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xgboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5ba71e9-082e-4cb5-88db-6dcd73e95ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_a_enc = le.fit_transform(y_train_a)\n",
    "y_test_a_enc = le.fit_transform(y_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3564fdcb-2e3e-4e40-8b58-d5017b278a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Creating Model Model creation successful!\n",
      "✔ Registering Hyper Parameter Recorder with Markov Backend. Recorder successfully registered.\n",
      "ℹ You can view the experiment at \u001b\\https://app.markovml.com/wsp-27m23rbvum/proj/3GEEgreNQVvGxs/experiments/hp-7i6amaWRFg2vbm3gYpfmsSX\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import markov\n",
    "\n",
    "hyper_parameters = {\"random_state\":5}\n",
    "xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=5)\n",
    "\n",
    "\n",
    "# Use the ExperimentRecorder constuctor provided by the MarkovML SDK\n",
    "# to create a new experiment recorder\n",
    "recorder_xgb = markov.ExperimentRecorder(\n",
    "    # Name of the experiment recording\n",
    "   name=\"Model 1 Xgboost experiment\",\n",
    "    # Project associated with the experiment\n",
    "    # project_id=my_project.project_id,\n",
    "    project_id = \"3GEEgreNQVvGxs\",\n",
    "    # Hyper-parameters used for model training\n",
    "   hyper_parameters = {\"random_state\":5},\n",
    "    # Additional notes (optional)\n",
    "    model_class=markov.ModelClass.TAGGING,\n",
    "    notes=\"This is a experiment describing the model-1 Xgboost\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "325c8e7e-4cec-46f5-8c2d-861f3ab15cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Starting recorder to track training data on markov backend.\n",
      "⚠ Please wait while we send the remaining data to the markov backend... Could not send all QUEUE_MESSAGE_TYPEs to the markov server!\n",
      "Accuracy: 79.31%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1401\n",
      "           1       0.76      0.78      0.77      1132\n",
      "\n",
      "    accuracy                           0.79      2533\n",
      "   macro avg       0.79      0.79      0.79      2533\n",
      "weighted avg       0.79      0.79      0.79      2533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with recorder_xgb:\n",
    "    xgb_clf.fit(x_train_a, y_train_a_enc)\n",
    "    y_pred = xgb_clf.predict(x_test_a)\n",
    "    y_pred_enc = le.fit_transform(y_pred)\n",
    "    acc = accuracy_score(y_pred_enc, y_test_a_enc)\n",
    "    recorder_xgb.add_record({\"accuracy\": acc})\n",
    "    cr = classification_report(y_pred_enc, y_test_a_enc)\n",
    "    recorder_xgb.add_record({\"classification_report\": cr})\n",
    "    cm = confusion_matrix(y_pred_enc, y_test_a_enc)\n",
    "    recorder_xgb.add_record({\"confusion_matrix\": cm})\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a_enc, y_pred_enc))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a_enc, y_pred_enc, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result/model1/Xgboost/\", \"task_a_cls_report_xgboost.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4818a717-ea0e-455a-a259-e7e39b2f2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7931306750888275\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model\n",
    "filename = './result/model1/Xgboost/Xgboost_model.pkl'\n",
    "pickle.dump(xgb_clf, open(filename, 'wb'))\n",
    "\n",
    "# load the model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# make predictions with the loaded model\n",
    "y_pred = loaded_model.predict(x_test_a)\n",
    "y_pred_enc = le.fit_transform(y_pred)\n",
    "\n",
    "# evaluate the loaded model\n",
    "acc = accuracy_score(y_pred_enc, y_test_a_enc)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7dd3fb4-3d9e-4067-afdc-38e30f7a07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def predict_sexism(text, model, tfidf, lemmatizer, stop_words):\n",
    "    text = process_text(text, lemmatizer, stop_words)\n",
    "    text_vec = tfidf.transform([text])\n",
    "    prediction = model.predict(text_vec)\n",
    "    return prediction[0]\n",
    "\n",
    "# test the function\n",
    "example_text = \"I was told no woman who had children under the age of 6 had any business being outside the home.\"\n",
    "pred = predict_sexism(example_text, loaded_model, tfidf, lemmatizer, stop_words)\n",
    "print(pred) # should print 'not sexist' or 'sexist'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab113726-0147-4ef8-9554-3009bf5808d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predicted\n",
       "0       0          1\n",
       "1       0          1\n",
       "2       1          1\n",
       "3       1          1\n",
       "4       0          1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "dict_data = {'actual': y_test_a_enc, 'predicted': y_pred_enc}\n",
    "df_xgb = pd.DataFrame(data=dict_data)\n",
    "# save the dataframe to a CSV file\n",
    "df_xgb.to_csv(\"./result/model1/Xgboost/recording_xgb.csv\")\n",
    "\n",
    "# display the first few rows of the dataframe\n",
    "df_xgb.head()\n",
    "# now just map the not sexist with 0 and sexist with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80407d00-3ce3-440f-9eef-342aee6f4619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markov.api.recording.evaluations.evaluation_recorder.EvaluationRecorder at 0x7f609fde80d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from markov import EvaluationRecorder\n",
    "evaluation_recorder_xgb = EvaluationRecorder(\n",
    "    name=f\"Evaluating {recorder_xgb.name}\",\n",
    "    notes=f\"Evaluation of model1 using MarkovML\",\n",
    "    model_id=recorder_xgb.model_id\n",
    ")\n",
    "\n",
    "evaluation_recorder_xgb.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49dcb2d1-a2a7-413d-9fb7-c800685e8dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload Progress : 100%|██████████| 3/3 [00:00<00:00,  4.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationRecordingFinishResponse(count=2533, recording_id='9LNQfVnKRHwDL8vh5ispDQg', return_code='OK', message='', run_id='Vnv2ESzVd4TFbRey8qr')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "from markov.api.schemas.model_recording import SingleTagInferenceRecord\n",
    "\n",
    "# create and register the recorder\n",
    "filepath = os.path.join('./result/model1/Xgboost/recording_xgb.csv')\n",
    "with open(filepath) as f:\n",
    "    for line in f:\n",
    "        # Assign a unique identifier for individual records\n",
    "        record_id = str(uuid.uuid4())\n",
    "        tokens = line.strip('\\n').split(',')\n",
    "        record = SingleTagInferenceRecord(\n",
    "            urid=record_id,\n",
    "            inferred=tokens[2],\n",
    "            actual=tokens[1],\n",
    "            score=float(tokens[0])\n",
    "        )\n",
    "        evaluation_recorder_xgb.add_record(record)\n",
    "outcome = evaluation_recorder_xgb.finish()\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ee73f63-b219-449f-9b93-e43f4ff21d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b357ca02-abaa-477c-a18a-f9788ed0f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Creating Model Model creation successful!\n",
      "✔ Registering Hyper Parameter Recorder with Markov Backend. Recorder successfully registered.\n",
      "ℹ You can view the experiment at \u001b\\https://app.markovml.com/wsp-27m23rbvum/proj/3GEEgreNQVvGxs/experiments/hp-4cyFFgRprjPgnpPEeAcxEjN\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import markov\n",
    "\n",
    "hyper_parameters = {}\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Use the ExperimentRecorder constuctor provided by the MarkovML SDK\n",
    "# to create a new experiment recorder\n",
    "recorder_rf = markov.ExperimentRecorder(\n",
    "    # Name of the experiment recording\n",
    "   name=\"Model-1 Random Forest experiment\",\n",
    "    # Project associated with the experiment\n",
    "    # project_id=my_project.project_id,\n",
    "    project_id = \"3GEEgreNQVvGxs\",\n",
    "    # Hyper-parameters used for model training\n",
    "   hyper_parameters = {},\n",
    "    # Additional notes (optional)\n",
    "    model_class=markov.ModelClass.TAGGING,\n",
    "    notes=\"This is a experiment describing the model-1 Random Forest\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef72ca7c-3e4d-498f-82fe-761115ca501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Starting recorder to track training data on markov backend.\n",
      "⚠ Please wait while we send the remaining data to the markov backend... Could not send all QUEUE_MESSAGE_TYPEs to the markov server!\n",
      "Accuracy: 81.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.84      0.82      0.83      1401\n",
      "      sexist       0.78      0.80      0.79      1132\n",
      "\n",
      "    accuracy                           0.81      2533\n",
      "   macro avg       0.81      0.81      0.81      2533\n",
      "weighted avg       0.81      0.81      0.81      2533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with recorder_rf:\n",
    "    rf_clf.fit(x_train_a, y_train_a)\n",
    "    rf_pred = rf_clf.predict(x_test_a)\n",
    "    acc = accuracy_score(rf_pred, y_test_a)\n",
    "    recorder_rf.add_record({\"accuracy\": acc})\n",
    "    cr = classification_report(y_test_a, rf_pred)\n",
    "    recorder_rf.add_record({\"classification_report\": cr})\n",
    "    cm = confusion_matrix(y_test_a, rf_pred)\n",
    "    recorder_rf.add_record({\"confusion_matrix\": cm})\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a, rf_pred))\n",
    "clsf_report = pd.DataFrame(classification_report(y_test_a, rf_pred, output_dict=True)).transpose()\n",
    "clsf_report.to_csv(os.path.join(os.path.curdir, \"result/model1/Random Forest/\", \"task_a_cls_report_random_forest.csv\"), index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d770ac3c-f148-45ae-8e1b-9cf93cbdaf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist       0.84      0.82      0.83      1401\n",
      "      sexist       0.78      0.80      0.79      1132\n",
      "\n",
      "    accuracy                           0.81      2533\n",
      "   macro avg       0.81      0.81      0.81      2533\n",
      "weighted avg       0.81      0.81      0.81      2533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model\n",
    "filename = './result/model1/Random Forest/RandomForest_model.pkl'\n",
    "pickle.dump(rf_clf, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# make predictions with the loaded model\n",
    "rf_pred = loaded_model.predict(x_test_a)\n",
    "\n",
    "# evaluate the loaded model\n",
    "acc = accuracy_score(rf_pred, y_test_a)\n",
    "print(\"Accuracy:\",str('{:04.2f}'.format(acc*100))+'%')\n",
    "print(classification_report(y_test_a, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c20ccc4-205a-4456-a23c-cbb709855dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexist\n"
     ]
    }
   ],
   "source": [
    "def predict_sexism(text, model, tfidf, lemmatizer, stop_words):\n",
    "    text = process_text(text, lemmatizer, stop_words)\n",
    "    text_vec = tfidf.transform([text])\n",
    "    prediction = model.predict(text_vec)\n",
    "    return prediction[0]\n",
    "\n",
    "# test the function\n",
    "example_text = \"I was told no woman who had children under the age of 6 had any business being outside the home.\"\n",
    "pred = predict_sexism(example_text, loaded_model, tfidf, lemmatizer, stop_words)\n",
    "print(pred) # should print 'not sexist' or 'sexist'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e553756-fbec-4656-9ba9-adef862fa2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25687</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23724</th>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17758</th>\n",
       "      <td>sexist</td>\n",
       "      <td>sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11829</th>\n",
       "      <td>not sexist</td>\n",
       "      <td>not sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual   predicted\n",
       "25687  not sexist  not sexist\n",
       "1163   not sexist  not sexist\n",
       "23724      sexist      sexist\n",
       "17758      sexist      sexist\n",
       "11829  not sexist  not sexist"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# create a dataframe with actual and predicted values\n",
    "dict_data = {'actual': y_test_a, 'predicted': rf_pred}\n",
    "df_rf = pd.DataFrame(data=dict_data)\n",
    "\n",
    "# save the dataframe to a CSV file\n",
    "df_rf.to_csv(\"./result/model1/Random Forest/recording_rf.csv\")\n",
    "\n",
    "# display the first few rows of the dataframe\n",
    "df_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528749ec-e5c6-4506-a785-ce26b1a6d5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<markov.api.recording.evaluations.evaluation_recorder.EvaluationRecorder at 0x7f3ea416d5b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from markov import EvaluationRecorder\n",
    "evaluation_recorder_rf = EvaluationRecorder(\n",
    "    name=f\"Evaluating {recorder_rf.name}\",\n",
    "    notes=f\"Evaluation of model1 using MarkovML\",\n",
    "    model_id=recorder_rf.model_id\n",
    ")\n",
    "\n",
    "evaluation_recorder_rf.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8970caef-7ee2-4303-ab1e-9e9bdf593e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload Progress : 100%|██████████| 3/3 [00:00<00:00,  3.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationRecordingFinishResponse(count=2533, recording_id='4g4AUYNE45oMH7G7PLTPGoB', return_code='OK', message='', run_id='3CGLd8GpbsW34EM84AC')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "from markov.api.schemas.model_recording import SingleTagInferenceRecord\n",
    "\n",
    "# create and register the recorder\n",
    "filepath = os.path.join('./result/model1/Random Forest/recording_rf.csv')\n",
    "with open(filepath) as f:\n",
    "    for line in f:\n",
    "        # Assign a unique identifier for individual records\n",
    "        record_id = str(uuid.uuid4())\n",
    "        tokens = line.strip('\\n').split(',')\n",
    "        record = SingleTagInferenceRecord(\n",
    "            urid=record_id,\n",
    "            inferred=tokens[2],\n",
    "            actual=tokens[1],\n",
    "            score=float(tokens[0])\n",
    "        )\n",
    "        evaluation_recorder_rf.add_record(record)\n",
    "outcome = evaluation_recorder_rf.finish()\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff72894-fb6e-4c05-8620-c069a0ec8976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
